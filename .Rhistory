library(ggolot2)
library(ggplot2)
?ggpairs
??ggpairs
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
require("easypackages") # to download and load packages fast
install.packages("eazypackages")
install.packages("easypackages")
require("easypackages") # to download and load packages fast
packages_to_load <- c("broom", "dplyr", "MASS", "tidyverse", "corrplot", "ggplot2", "GGally")
install.packages("stingi", dependencies = TRUE) #these are needed for corrplot
install.packages("broom", dependencies = TRUE) #these are needed for corrplot
packages_to_load <- c("broom", "dplyr", "MASS", "tidyverse", "corrplot", "ggplot2", "GGally")
libraries(packages_to_load) # load
?easypackages
library(easypackages)
??easypackages
install.packages("tidyverse")
packages(packages_to_load, prompt = TRUE) # lock'n'load install/load
packages(packages_to_load, prompt = TRUE) # lock'n'load install/load
libraries(packages_to_load) # load
data("Boston")
str(      Boston)
summary(  Boston)
dim(      Boston)
pairs(Boston)
p <-ggpairs(Boston, mapping = aes(alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
p
my_fn <- function(data, mapping, ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point() +
geom_smooth(method=loess, fill="red", color="red", ...) +
geom_smooth(method=lm, fill="blue", color="blue", ...)
p
}
g = ggpairs(Boston,columns = c(1:14), lower = list(continuous = my_fn))
g
cor_matrix<-cor(Boston) %>% round(digits = 2)
cor_matrix
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
str(      Boston)
Boss <- as.data.frame(scale(Boston))
summary(crime)
bins <- quantile(boston_scaled$crim)
bins
crime <- as.data.frame(scale(Boston))
summary(crime)
summary(Boston_scaled$crime)
Boston_scaled <- as.data.frame(scale(Boston))
summary(Boston_scaled$crime)
Boston_scaled
bins
bins <- quantile(Boston_scaled$crime)
bins
names(Boston)
summary(Boston_scaled$crim)
bins <- quantile(Boston_scaled$crim)
bins
crime <- cut(boston_scaled$crime, breaks = bins, include.lowest= TRUE, label = c("low","med_low","med_high", "high"))
crime <- cut(Boston_scaled$crime, breaks = bins, include.lowest= TRUE, label = c("low","med_low","med_high", "high"))
crime <- cut(Boston_scaled$crim, breaks = bins, include.lowest= TRUE, label = c("low","med_low","med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
Boston_scaled <- dplyr::select(Boston_scaled, -crim)
Boston_scaled <- data.frame(Boston_scaled, crime)
n <-nrow(Boston)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
train <- Boston_scaled[ind,]
test <- Boston_scaled[-ind,]
correct_classes <-test$crime
test <- dplyr::select(test, -crime)
lda.fit <- lda(crime ~., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(classes, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
?plot
classes
plot(classes, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 2)
install.packages("devtools")
library(devtools)
install_github("fawda123/ggord")
ord <- lda(Species ~ ., iris, prior = rep(1, 3)/3)
ggord(ord, iris$Species)
library(ggord)
ord <- lda(Species ~ ., iris, prior = rep(1, 3)/3)
ggord(ord, iris$Species)
ggord(lda.fir, train$crime)
ggord(lda.fit, train$crime)
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted = lda.pred$class)
summary(dist_eu)
dist_eu <- dist(Boston)
summary(dist_eu)
dist_man <- dist(Boston, method="manhattan")
summary(dist_man)
km <-kmeans(Boston, centers = 4)
pairs(Boston[6:10], col = km$cluster)
set.seed(123)
k_max <- 4
twcss <- sapply(1:k_max, function(k){kmeans(Boston, k)$tot.withinss})
qplot(x = 1:k_max, y = twcss, geom = 'line')
km <-kmeans(Boston, centers = 2)
pairs(Boston, col = km$cluster)
pairs(Boston[6:10], col = km$cluster)
fit <- sbf(
form = Boston$crim ~ .,
data = Boston[c(1:14)], method = "glmnet", # Dalc and Walc are dropped as they are the parameters high_use is based on, D1:D3, dropped as well, since grades are known only after students are done with the studies (especially final exam G3)
tuneGrid=expand.grid(.alpha = .01, .lambda = .1),
preProc = c("center", "scale"),
trControl = trainControl(method = "none"),
sbfControl = sbfControl(functions = caretSBF, method = 'cv', number = 10)
)
install.packages("caret")
library(caret)
fit <- sbf(
form = Boston$crim ~ .,
data = Boston[c(1:14)], method = "glmnet", # Dalc and Walc are dropped as they are the parameters high_use is based on, D1:D3, dropped as well, since grades are known only after students are done with the studies (especially final exam G3)
tuneGrid=expand.grid(.alpha = .01, .lambda = .1),
preProc = c("center", "scale"),
trControl = trainControl(method = "none"),
sbfControl = sbfControl(functions = caretSBF, method = 'cv', number = 10)
)
fit
m <- lm(crim ~ . , data=Boston)
m2 <- lm(crim ~ age + black + dis +indus + lstat, data=Boston)
m3 <- lm(crim ~ dis +tax, data=Boston)
AIC(m,m2,m3)
step(m, direction = "both")
m4 <- lm(crim ~ zn + nox + dis + rad + ptratio + black +
lstat + medv, data = Boston)
AIC(m,m2,m3, m4)
par(mfrow=c(2,2))
plot(m4)
plot(m)
ggord(lda.fit, train$crime)
?ggord
ggord(lda.fit, train$crime, ellipse = TRUE)
ggord(lda.fit, train$crime, ellipse_pro = 0.90)
ggord(lda.fit, train$crime, ellipse_pro = 0.95)
ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3)
ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 5)
library("ggthemes")
library("scales")
install.packages("ggthemes", "scales")
install.packages("scales")
install.packages("scales")
library("ggthemes")
library("scales")
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha = 0.3)
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3)
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2)
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2, cols = c("rad", "zn", "nox", "dis"))
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2, axes = c("rad", "zn", "nox", "dis"))
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2, axes = c("1", "2", "3", "4"))
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2, axes = c("1", "2", "3", "4"))
g  + geom_rangeframe() +theme_tufte()
names(train)
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2, axes = c("zn"))
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2, axes = c("zn", "rad"))
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, alpha_el = 0.3, size = 2)
g  + geom_rangeframe() +theme_tufte()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 3, ext = 2, alpha_el = 0.3, size = 2)
g  + geom_rangeframe() +theme_tufte()
g  +theme_tufte()  #+ geom_rangeframe()
g  +theme_tufte()  + geom_rangeframe()
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 2, alpha_el = 0.3, size = 2)
g  +theme_tufte()  + geom_rangeframe()
my_fn <- function(data, mapping, ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point() +
geom_smooth(method=loess, fill="red", color="red", ...) +
geom_smooth(method=lm, fill="blue", color="blue", ...)
p
}
g = ggpairs(Boston,columns = c(1:14), lower = list(continuous = my_fn))
g
install.packages("fitdistrplus")
rmarkdown::render('index.Rmd')
Show Traceback
warnings(9)
knit_with_parameters('C:/Git/IODS-project/index.Rmd')
BostonS <- scale(Boston) # standardize variables
wss <- (nrow(Bostons)-1)*sum(apply(BostonS,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(BostonS,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
km <-kmeans(BostonS, centers = 3)
BostonS <- scale(Boston) # standardize variables
wss <- (nrow(BostonS)-1)*sum(apply(BostonS,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(BostonS,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
km <-kmeans(BostonS, centers = 4)
pairs(BostonS[6:10], col = km$cluster)
km$cluster
km <-kmeans(BostonS, centers = 2)
# plot the Boston dataset with clusters
pairs(BostonS[6:10], col = km$cluster)
pairs(BostonS, col = km$cluster)
km <-kmeans(BostonS, centers = 4)
pairs(BostonS, col = km$cluster)
pairs(BostonS[6:10], col = km$cluster)
pairs(BostonS[2:10], col = km$cluster)
km
cluster
km$cluster
km
summary(km)
summary(km$centers)
f <- ggord(km, BostonS$crime, ellipse_pro = 0.95, vec_ext = 2, alpha_el = 0.3, size = 2)
f  + theme_tufte()  + geom_rangeframe()
lda.fit
lda.fit <- lda(crime ~., data = train)
ggpairs(BostonS, col=km$cluster)
install.packages("plotly")
library(plotly)
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
Boston_scaled <- as.data.frame(scale(Boston))
# create a quantile vector of crime and print it
bins <- quantile(Boston_scaled$crim)
bins
# create a categorical variable 'crim'
crime <- cut(Boston_scaled$crim, breaks = bins, include.lowest= TRUE, label = c("low","med_low","med_high", "high"))
# remove original crim from the dataset
Boston_scaled <- dplyr::select(Boston_scaled, -crim)
# add the new categorical value to scaled data
Boston_scaled <- data.frame(Boston_scaled, crime)
# number of rows in the Boston dataset
n <-nrow(Boston)
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
# create train set
train <- Boston_scaled[ind,]
# create test set
test <- Boston_scaled[-ind,]
# save the correct classes from test data
correct_classes <-test$crime
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
summary(train)
# linear discriminant analysis
lda.fit <- lda(crime ~., data = train)
# print the lda.fit object
lda.fit
g <- ggord(lda.fit, train$crime, ellipse_pro = 0.95, vec_ext = 2, alpha_el = 0.3, size = 2)
g  + theme_tufte()  + geom_rangeframe()
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
# k-means clustering
BostonS <- scale(Boston) # standardize variables
wss <- (nrow(BostonS)-1)*sum(apply(BostonS,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(BostonS,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
km <-kmeans(BostonS, centers = 4)
# plot the Boston dataset with clusters
pairs(BostonS, col = km$cluster)
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')
?plot_ly
summary(matrix_product)
summary(matrix_product$LD1)
matrix_product$LD1
