---
title: "Chapter 3. Logistic regression"
author: "Tuure Parviainen"
date: "November 19, 2017"
output: html_document
---

## Chapter 2. Logistic regression

This time I had much less time to use for this exercise, so I used the methods given and didn't try anything extra.

Data Set Information:
   
This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
# To empty the memory after the excercise before this
rm(list=ls())
# Load data
alc <- read.csv(file = "data/ex3alc.csv")
# Libraries
library(dplyr) # data manipulation
library(caret) # findCorrelation algorithm
library(ggcorrplot) # plot the correlations
library(ggplot2)
library(GGally)
library(ggcorrplot)
library(caret)

glimpse(alc)
summary(alc)

# The data set is combined from two different files from the machine learning repository


#alc is the full dataset, we take numeric values for correlation analysis
alc2 <- select_if(alc, is.numeric)
correlations <- abs(cor(alc2, use="pairwise.complete.obs"))
#correlation of all parameters with absolute numbers
correlations.selected <- findCorrelation(correlations, cutoff = .5, exact = TRUE)
#colums with to select by cutoff 0.7
#Making sure that grades are part of the correlation table
grade.columns <- 15:17
correlations.selected <- union(correlations.selected,grade.columns )
# calculating the variables
corr <- cor(alc2[c(correlations.selected)])
#correlations of narrow selection and grades variables G1, G2, G3

# Ploting correaltions
ggcorrplot(corr, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("tomato2", "white", "springgreen3"), 
           title="Correlogram of PKY", 
           ggtheme=theme_bw)

# Now we see the highest correlation to G1:G3 is with age, Medu, alc_use and Walc. Since alc_use and Walc have high correlation, only better one is selected for the analysis. G3 is the final grade, so we first try to only predict that and drop the G1 and G2, even thought it would be likely that they would be good predictors of G3. 

# So we want to predict the Final grade of the students, with their alcohol use, age and their mothers education level.

# I hypotise that alcohol use would reduce the performance and mothers educational level would increase their performance.

my_fn <- function(data, mapping, ...){
  p <- ggplot(data = data, mapping = mapping) +
    geom_point() +
    geom_smooth(method=loess, fill="red", color="red", ...) +
    geom_smooth(method=lm, fill="blue", color="blue", ...)
  p
}
g = ggpairs(alc2,columns = c(correlations.selected), lower = list(continuous = my_fn))
g
# Lets add some factor variables to the data
names.selected <- colnames(alc2[correlations.selected])
alc3 <- subset(alc, select=c(names.selected, "sex", "school", "guardian", "activities"))

p <-ggpairs(alc, mapping = aes(col = sex, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
p

# The categorial variables are quite similar and does not give much indication other than, that the very alcohol use is higher with males and almost no alcohol use is more common with females.

m <- glm(G3 ~ alc_use + Walc + age + Medu, family = "gaussian", data = alc3)
m2 <- glm(G3 ~ alc_use + age + Medu, family = "gaussian", data = alc3)
deviance(m2)/m2$null.deviance
AIC(m,m2)
par(mfrow=c(2,2))
plot(m2)
# Akaike information criteria gives similar result, so as hypotised the Walc is dropped as they have covariance, that way we achive the most parsimonious model.

# Model explains (R^2) 91 % of the variation without the help of G1 and G2.

# !!! Oh, I only realized at this point that the target variable was supposed to be high/low alcohol consumption, now I realize why logistic regression in this case... !!!

# I suppose I need to do another selection for parameters for this case..

# Maybe this might help...
https://stackoverflow.com/questions/30618847/how-to-apply-filter-based-feature-selection-for-logistic-regression-in-rs-caret

# compute odds ratios (OR)
OR <- coef(m) %>% exp
# compute confidence intervals (CI)
CI <- exp(confint(m))
cbind(OR, CI)
```

















#Extra

```{r, eval=FALSE}
# I found this very useful in the DataCamp exercises

# produce summary statistics by group with piping variable #>#
alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade=mean(G3))

```



## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
